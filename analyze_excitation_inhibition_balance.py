# analyze_excitation_inhibition_balance.py --- 
# 
# Filename: analyze_excitation_inhibition_balance.py
# Description: 
# Author: 
# Maintainer: 
# Created: Wed Nov 14 12:36:04 2012 (+0530)
# Version: 
# Last-Updated: Sat Nov 24 17:37:59 2012 (+0530)
#           By: subha
#     Update #: 836
# URL: 
# Keywords: 
# Compatibility: 
# 
# 

# Commentary: 
# 
# This is for analyzing the excitation inhibition balance
# 
# 

# Change log:
# 
# 
# 
# 

# Code:



import h5py as h5
import os
print os.getcwd()
from datetime import datetime
from get_files_by_ts import *
import numpy as np
from matplotlib import pyplot as plt
from matplotlib._pylab_helpers import Gcf
import random

import analyzer

class TraubData(object):
    """Wrapper for data files generated by traub model simulation

    members:

    fd: hdf5 file handle associated with this object

    cellcounts: cellcount_tuple containing the counts for each cell type

    timestamp: datetime.datetime timestamp of the simulation

    bg_stimulus: array representing timeseries for background stimulus

    probe_stimulus: array representing timeseries for probe stimulus

    simtime: duration of the simulation
    """
    def __init__(self, fname):
        netfilename = os.path.join(os.path.dirname(fname),
                                   os.path.basename(fname).replace('data_', 'network_').replace('.h5', '.h5.new'))
        self.fdata = None
        self.fnet = None
        try:
            self.fdata = h5.File(fname, 'r')
            self.fnet = h5.File(netfilename)
        except IOError as e:
            print e
        self.__get_cellcounts()
        self.__get_timestamp()        
        self.__get_stimuli()
        self.spikes = dict([(cell, np.asarray(self.fdata['/spikes'][cell])) 
                            for cell in self.fdata['/spikes']])
        self.__get_schedinfo()
        self.__get_synapse()
        self.__get_stimulated_cells()
        print 'Loaded', fname

    def __del__(self):
        if self.fdata is not None:
            self.fdata.close()
        if self.fnet is not None:
            self.fnet.close()

    def __get_cellcounts(self):
        if self.fdata is None:
            return
        try:
            cc = dict([(k, int(v)) for k, v in np.asarray(self.fdata['/runconfig/cellcount']) if k in cellcount_tuple._fields])                
            print self.fdata.filename, cc
            self.cellcounts = cellcount_tuple(**cc)
        except KeyError, e:
            print e           

    def __get_timestamp(self):
        try:
            ts = self.fdata.attrs['timestamp']
            self.timestamp = datetime.strptime(ts, '%Y-%m-%d %H:%M:%S')
        except (ValueError, KeyError):
            # Older files do not have the time stamp attribute
            # But all data files are named according to the scheme:
            # data_YYYYmmdd_HHMMSS_PID.h5
            tokens = os.path.basename(self.fdata.filename).split('_')
            ts = tokens[1] + tokens[2]
            self.timestamp = datetime.strptime(ts, '%Y%m%d%H%M%S')

    def __get_stimuli(self):
        try:
            self.bg_stimulus = np.asarray(self.fdata['/stimulus/stim_bg'])
            self.probe_stimulus = np.asarray(self.fdata['/stimulus/stim_probe'])
        except KeyError as e:
            print e
        
    def __get_schedinfo(self):
        schedinfo = dict(self.fdata['/runconfig/scheduling'])
        self.simtime = float(schedinfo['simtime'])
        self.simdt = float(schedinfo['simdt'])
        self.plotdt = float(schedinfo['plotdt'])

    def __get_synapse(self):
        try:
            self.synapse = np.asarray(self.fnet['/network/synapse'])
        except KeyError as e:
            print self.fdata.filename
            print e
            raise(e)
            
    def get_notes(self):
        return self.fdata.attrs['notes']
        
    def presynaptic(self, cellname):
        indices = np.char.startswith(self.synapse['dest'], cellname)
        return [row[0] for  \
                row in np.char.split(self.synapse['source'][indices], '/')]

    def postsynaptic(self, cellname):
        indices = np.char.startswith(self.synapse['source'], cellname)
        return [row[0] for  \
                row in np.char.split(self.synapse['dest'][indices], '/')]

    def __get_stimulated_cells(self):
        """Create the attributes `bg_cells` and `probe_cells` - lists
        of cells that received background stimulus and probe stimulus
        resepctively.
        
        """
        if hasattr(self, 'bg_cells'):
            return
        stiminfo = np.asarray(self.fnet['/stimulus/connection'])
        self.bg_cells = [ token[-2] \
                          for token in np.char.split(stiminfo[np.char.endswith(stiminfo['f0'], 'stim_bg')]['f1'], '/')]
        self.probe_cells = [token[-2] \
                            for token in np.char.split(stiminfo[np.char.endswith(stiminfo['f0'], 'stim_probe')]['f1'], '/')]

    def get_bg_stimulated_cells(self, celltype):
        post_cells = []
        for cell in self.bg_cells:
            post_cells += self.postsynaptic(cell)
        return [cell for cell in set(post_cells) if cell.startswith(celltype)]
        
    def get_probe_stimulated_cells(self, celltype):
        post_cells = []
        for cell in self.probe_cells:
            post_cells += self.postsynaptic(cell)
        return [cell for cell in set(post_cells) if cell.startswith(celltype)]

    def bg_stimulus_spike_correlations(self, celltype, window):
        cells = self.get_bg_stimulated_cells(celltype)
        raise NotImplementedError('TODO: finish')
        

def close_all_figures():
    current_figures = [fig_manager.canvas.figure for fig_manager in Gcf.get_all_fig_managers()]
    for fig in current_figures:
        fig.close()

def invert_container_map(container_map):
    """Get the inverse map of container_map, container_map:
    defaultdict(some_container_type)

    Returns a dict mapping each entry of the containers (values) to
    the key corresponding to the container object

    """
    return {v:k 
            for k, vlist in container_map.items() 
            for v in vlist}

def randomized_plot(file_stub_map, plot_function):
    pass

def plot_spike_rasters(cells, data, colordict):
    """Plot spike raster of cells from `cells` list using data in
    `data` list.

    `cells` and `data` must be of same length. data[i] contains spike
    times for cells[i].

    `colordict` dictionary contains the mapping from celltype to plot
    color.
    
    """
    for index, (cell, spiketimes) in enumerate(zip(cells, data)):
        plt.plot(spiketimes, np.ones(len(spiketimes)) * index, 
                 color=colordict[cell.split('_')[0]],
                 ls='',
                 marker=',', 
                 mew=0)
        
def classify_cells(cells):
    """Return a dict maping celltype to list of cells."""
    categories = defaultdict(list)
    for cell in cells:
        celltype = cell.split('_')[0]
        categories[celltype].append(cell)
    return categories

def plot_population_spike_histogram(trbdatalist, timerange, bins, colordict):
    """Plot histogram of spike counts for different celltypes.
    
    trbdatalist: list TraubData objects wrapping the data files

    timerange: 2-tuple time window to consider for the histogram

    bins: bin positions for histogram

    colordict: celltype-color dictionary
    """
    figures = []
    for data in trbdatalist:
        figure = plt.figure(data.fdata.filename)
        figure.suptitle(data.fdata.filename)
        figures.append(figure)
        celltype_spiketrain_map = defaultdict(list)
        for cell, spikenode in data.spikes.items():
            celltype = cell.split('_')[0]
            # Ignore ectopic spikes and incorrect celltype names
            if celltype not in cellcount_tuple._fields:
                continue
            spiketrain = np.asarray(spikenode)
            chunk = spiketrain[(spiketrain >= timerange[0]) & 
                               (spiketrain < timerange[1])]
            if len(chunk) > 0:
                celltype_spiketrain_map[celltype].append(chunk)
        for ax_index, (celltype, spiketrains) in enumerate(celltype_spiketrain_map.items()):
            ax = figure.add_subplot(len(celltype_spiketrain_map), 1, ax_index+1)
            spike_times = np.concatenate(spiketrains)
            n, bins, patches = ax.hist(spike_times,
                                       bins, 
                                       weights=np.ones(len(spike_times))/data.cellcounts._asdict()[celltype], 
                                       facecolor=colordict[celltype], 
                                       ec='none', 
                                       alpha=0.5, 
                                       label=celltype)
            max_height = max([p.get_bbox().get_points()[1][1] for p in patches])
            startindex = int(timerange[0]/data.plotdt+0.5)
            endindex = int(timerange[1]/data.plotdt+0.5) + 1            
            bg_stimulus = data.bg_stimulus[startindex:endindex]
            scale = max_height / max(bg_stimulus)
            ts = np.linspace(timerange[0], timerange[1], len(bg_stimulus))
            ax.plot(ts, bg_stimulus*scale, 'b-.', alpha=0.4)
            plt.legend()
        print 'plotted', data.fdata.filename
        figure.set_size_inches(6,6)
        figure.savefig(os.path.basename(data.fdata.filename)+'.hist.png')
    return figures

def randomized_spike_rasters_allcelltype(category_map, data_map, cellcounts, colordict):
    """Display spike rasters for all cell types with randomized
    labels.

    category_map: map from cellcounts to data file paths with that count

    data_map: map from file paths to {cellname: spike train} dict

    cellcounts: cellcount_tuple specifying number of cells to plot for each cell type

    colordict: map from celltype to color-string for the plot color

    """
    cellcounts = cellcounts._asdict()
    file_category_map = invert_container_map(category_map)
    files = file_category_map.keys()
    random.shuffle(files)
    stim_data = load_stim_data(files)
    simtimes = get_simtime(files)
    file_figtitle_map = {}
    file_fig_map = {}    
    for figindex, fname in enumerate(files):
        fig = plt.figure(figindex+1)
        file_fig_map[fname] = fig
        file_figtitle_map[fname] = figindex + 1
        fdata = data_map[fname]
        cc = defaultdict(list) # dict from cell type to cells
        cells = sorted(fdata.keys())                
        celltype_cell_map = classify_cells(cells)
        cells_to_plot = []
        for celltype, cells in celltype_cell_map.items():
            cells_to_plot += cells[:cellcounts[celltype]]
        data_to_plot = [fdata[cell] for cell in cells_to_plot]
        plot_spike_rasters(cells_to_plot, data_to_plot, colordict)
        plt.plot(np.linspace(0, simtimes[fname], len(stim_data[fname][0])), stim_data[fname][0]*1e9*len(cells_to_plot), alpha=0.2)
    with open('filetofigure_%s.csv' % 
              (datetime.now().strftime('%Y%m%d_%H%M%S')), 'w') as fd:        
        fd.write('filename, figure, %s\n' % (', '.join(cellcount_tuple._fields)))
        for cc, files in category_map.items():
            for x in cc:
                print x
                print str(x)
            counts = ', '.join([str(c) for c in cc])
            print counts
            for fname in files:
                fd.write('%s, %d, %s\n' % (fname, file_figtitle_map[fname], counts))
    plt.show()
    for filename, figure in file_fig_map.items():
        figure.set_size_inches(4, 3)
        figfile = os.path.basename(filename)+'.png'
        figure.savefig(figfile)
        print 'Saved', figfile


def display_more_tcr_stimulated_spike_hist(colordict):
    filenames = []
    with open('many_tcr_stimulated.txt', 'r') as filelist:
        for line in filelist:
            filename = line.strip()
            if filename:
                filenames.append(filename)
    handles = []
    for fname in filenames:
        try:
            fd = TraubData(fname)
            handles.append(fd)
        except (IOError, KeyError) as e:
            print e
    good_files = []    
    for fd in handles:
        if len(fd.bg_cells) > 5 \
          and fd.simtime >= 10.0 \
          and fd.cellcounts.TCR == 100 \
          and fd.cellcounts.SpinyStellate == 240 \
          and fd.cellcounts.SupPyrRS == 0 \
          and fd.cellcounts.SupLTS == 0 \
          and fd.cellcounts.SupBasket == 0 \
          and fd.cellcounts.SupPyrFRB == 0 \
          and fd.cellcounts.SupAxoaxonic == 0 \
          and fd.cellcounts.nRT == 0:
          good_files.append(fd)
    plot_population_spike_histogram(good_files, (0, 10.0), np.arange(0, 10.0, 5e-3), colordict)

            
        
if __name__ == '__main__':    
    colordict = load_celltype_colors()
    display_more_tcr_stimulated_spike_hist(colordict)    
    plt.show()
    # These simulations for excitation inhibition balance were done from 2012-09-19 till 2012-11-??
    # filenames = find_files('/data/subha/rsync_ghevar_cortical_data_clone', '-iname', 'data_*.h5') # Find all data files in the directory

    # current_fts = get_fname_timestamps(filenames, '20110101', '20120920') 
    # handles = []
    # for fname in current_fts.keys():
    #     try:
    #         handles.append(TraubData(fname))
    #     except (IOError, KeyError) as e:
    #         print e
    # print '=== printing filenames and notes ==='    
    # candidate_files = []
    # for fd in handles:
    #     if len(fd.bg_cells) > 5 and fd.simtime >= 10.0 \
    #         and fd.cellcounts.SpinyStellate == 240 \
    #         and fd.cellcounts.TCR == 100:
    #         candidate_files.append(fd)
    #         print '^', fd.fdata.filename
    #         print '  ', fd.cellcounts
            
    # plot_population_spike_histogram(candidate_files, (0, 10.0), np.arange(0, 10.0, 5e-3), colordict)
    # plt.show()

    
    # categories = classify_files_by_cellcount(current_fts.keys())
    # # After categorising the good files, we work with only those files
    # # with 240 spiny stellate cells (others test simulations)
    # goodfiles = {cc: files for cc, files in categories.items() if cc.SpinyStellate == 240}
    # data = [TraubData(filename) for filenamelist in goodfiles.values() for filename in filenamelist]
    # print 'Loaded data'
    # for d in data:
    #     print d.fdata.filename
    #     print d.bg_cells
    #     cell_stimcount_list = []
    #     for cell in d.get_bg_stimulated_cells('SpinyStellate'):
    #         pre_cells = set([pre for pre in d.presynaptic(cell)])
    #         stim_pre_cells = pre_cells.intersection(set(d.bg_cells))
    #         cell_stimcount_list.append((cell, len(stim_pre_cells)))
    #     for cell, stim_count in sorted(cell_stimcount_list, key=itemgetter(1)):
    #         print cell, stim_count
            
    #     print d.probe_cells
    #     print 'Probe stimulated SS cells:'
    #     probed_cells = d.get_probe_stimulated_cells('SpinyStellate')
    #     print len(probed_cells)
        

    #============================================================
    # The following code plots population spike count histogram
    # start = 15.0
    # end = 20.0 + data[0].simdt
    # plot_population_spike_histogram(data, (start, end), np.arange(start, end, 5e-3), colordict)
    # print 'Created plots'
    # plt.show()
    # Population spike count histogram till here
    #============================================================
    # The following code is for plotting spike rasters for SpinyStellate and TCR cells
    # cellcounts=cellcount_tuple(SupPyrRS=0,
    #                            SupPyrFRB=0,
    #                            SupBasket=0,
    #                            SupAxoaxonic=0,
    #                            SupLTS=0,
    #                            SpinyStellate=240,
    #                            TuftedIB=0,
    #                            TuftedRS=0,
    #                            DeepBasket=0,
    #                            DeepAxoaxonic=0,
    #                            DeepLTS=0,
    #                            NontuftedRS=0,
    #                            TCR=100,
    #                            nRT=0)
    # data = {}
    # for cc, fnames in goodfiles.items():        
    #     data.update(load_spike_data(fnames))
    # print 'Loaded data from', len(data), 'files'
    # randomized_spike_rasters_allcelltype(goodfiles, data, cellcounts, colordict)
    # Till here
    #============================================================
        
                
# 
# analyze_excitation_inhibition_balance.py ends here
