# analyze_excitation_inhibition_balance.py --- 
# 
# Filename: analyze_excitation_inhibition_balance.py
# Description: 
# Author: 
# Maintainer: 
# Created: Wed Nov 14 12:36:04 2012 (+0530)
# Version: 
# Last-Updated: Tue Nov 20 18:17:58 2012 (+0530)
#           By: subha
#     Update #: 701
# URL: 
# Keywords: 
# Compatibility: 
# 
# 

# Commentary: 
# 
# This is for analyzing the excitation inhibition balance
# 
# 

# Change log:
# 
# 
# 
# 

# Code:

import h5py as h5
import os
from datetime import datetime
from get_files_by_ts import *
import numpy as np
from matplotlib import pyplot as plt
from matplotlib._pylab_helpers import Gcf
import random

import analyzer

class TraubData(object):
    """Wrapper for data files generated by traub model simulation

    members:

    fd: hdf5 file handle associated with this object

    cellcounts: cellcount_tuple containing the counts for each cell type

    timestamp: datetime.datetime timestamp of the simulation

    bg_stimulus: array representing timeseries for background stimulus

    probe_stimulus: array representing timeseries for probe stimulus

    simtime: duration of the simulation
    """
    def __init__(self, fname):
        self.fdata = h5.File(fname, 'r')
        netfilename = os.path.join(os.path.dirname(fname),
                                   os.path.basename(fname).replace('data_', 'network_').replace('.h5', '.h5.new'))
        self.fnet = h5.File(netfilename)
        self.__get_cellcounts()
        self.__get_timestamp()        
        self.__get_stimuli()
        self.spikes = dict([(cell, np.asarray(self.fdata['/spikes'][cell])) 
                            for cell in self.fdata['/spikes']])
        self.__get_schedinfo()
        self.__get_synapse()
        self.__get_stimulated_cells()
        print 'Loaded', fname

    def __del__(self):
        self.fdata.close()
        self.fnet.close()

    def __get_cellcounts(self):
        try:
            cc = dict([(k, int(v)) for k, v in np.asarray(self.fdata['/runconfig/cellcount'])])                
            self.cellcounts = cellcount_tuple(**cc)
        except KeyError, e:
            print e           

    def __get_timestamp(self):
        try:
            ts = self.fdata.attrs['timestamp']
            self.timestamp = datetime.strptime(ts, '%Y-%m-%d %H:%M:%S')
        except (ValueError, KeyError):
            # Older files do not have the time stamp attribute
            # But all data files are named according to the scheme:
            # data_YYYYmmdd_HHMMSS_PID.h5
            tokens = os.path.basename(self.fdata.filename).split('_')
            ts = tokens[1] + tokens[2]
            self.timestamp = datetime.strptime(ts, '%Y%m%d%H%M%S')

    def __get_stimuli(self):
        try:
            self.bg_stimulus = np.asarray(self.fdata['/stimulus/stim_bg'])
            self.probe_stimulus = np.asarray(self.fdata['/stimulus/stim_probe'])
        except KeyError as e:
            print e
        
    def __get_schedinfo(self):
        schedinfo = dict(self.fdata['/runconfig/scheduling'])
        self.simtime = float(schedinfo['simtime'])
        self.simdt = float(schedinfo['simdt'])
        self.plotdt = float(schedinfo['plotdt'])

    def __get_synapse(self):
        self.synapse = np.asarray(self.fnet['/network/synapse'])
        
    def presynaptic(self, cellname):
        indices = np.char.startswith(self.synapse['dest'], cellname)
        return [row[0] for  \
                row in np.char.split(self.synapse['source'][indices], '/')]

    def postsynaptic(self, cellname):
        indices = np.char.startswith(self.synapse['source'], cellname)
        return [row[0] for  \
                row in np.char.split(self.synapse['dest'][indices], '/')]

    def __get_stimulated_cells(self):
        """Create the attributes `bg_cells` and `probe_cells` - lists
        of cells that received background stimulus and probe stimulus
        resepctively.
        
        """
        if hasattr(self, 'bg_cells'):
            return
        stiminfo = np.asarray(self.fnet['/stimulus/connection'])
        self.bg_cells = stiminfo[np.char.endswith(stiminfo['f0'], 'stim_bg')]['f1']
        self.probe_cells = stiminfo[np.char.endswith(stiminfo['f0'], 'stim_probe')]['f1']

    def bg_stimulus_spike_correlations(self, celltype, window):
        raise NotImplementedError('TODO')

def close_all_figures():
    current_figures = [fig_manager.canvas.figure for fig_manager in Gcf.get_all_fig_managers()]
    for fig in current_figures:
        fig.close()

def invert_container_map(container_map):
    """Get the inverse map of container_map, container_map:
    defaultdict(some_container_type)

    Returns a dict mapping each entry of the containers (values) to
    the key corresponding to the container object

    """
    return {v:k 
            for k, vlist in container_map.items() 
            for v in vlist}

def randomized_plot(file_stub_map, plot_function):
    pass

def plot_spike_rasters(cells, data, colordict):
    """Plot spike raster of cells from `cells` list using data in
    `data` list.

    `cells` and `data` must be of same length. data[i] contains spike
    times for cells[i].

    `colordict` dictionary contains the mapping from celltype to plot
    color.
    
    """
    for index, (cell, spiketimes) in enumerate(zip(cells, data)):
        plt.plot(spiketimes, np.ones(len(spiketimes)) * index, 
                 color=colordict[cell.split('_')[0]],
                 ls='',
                 marker=',', 
                 mew=0)
        
def classify_cells(cells):
    """Return a dict maping celltype to list of cells."""
    categories = defaultdict(list)
    for cell in cells:
        celltype = cell.split('_')[0]
        categories[celltype].append(cell)
    return categories

def plot_population_spike_histogram(trbdata, timerange, bins, colordict):
    """Plot histogram of spike counts for different celltypes.
    
    trbdata: list TraubData objects wrapping the data files

    timerange: 2-tuple time window to consider for the histogram

    bins: bin positions for histogram

    colordict: celltype-color dictionary
    """
    figures = []
    for data in trbdata:
        figure = plt.figure(data.fdata.filename)
        figure.suptitle(data.fdata.filename)
        figures.append(figure)
        celltype_spiketrain_map = defaultdict(list)
        for cell, spikenode in data.spikes.items():
            spiketrain = np.asarray(spikenode)
            chunk = spiketrain[(spiketrain >= timerange[0]) & 
                               (spiketrain < timerange[1])]
            if len(chunk) > 0:
                celltype_spiketrain_map[cell.split('_')[0]].append(chunk)
        for ax_index, (celltype, spiketrains) in enumerate(celltype_spiketrain_map.items()):
            ax = figure.add_subplot(len(celltype_spiketrain_map), 1, ax_index+1)
            spike_times = np.concatenate(spiketrains)
            n, bins, patches = ax.hist(spike_times,
                                       bins, 
                                       weights=np.ones(len(spike_times))/data.cellcounts._asdict()[celltype], 
                                       facecolor=colordict[celltype], 
                                       ec='none', 
                                       alpha=0.5, 
                                       label=celltype)
            max_height = max([p.get_bbox().get_points()[1][1] for p in patches])
            startindex = int(timerange[0]/data.plotdt+0.5)
            endindex = int(timerange[1]/data.plotdt+0.5) + 1            
            bg_stimulus = data.bg_stimulus[startindex:endindex]
            scale = max_height / max(bg_stimulus)
            ts = np.linspace(timerange[0], timerange[1], len(bg_stimulus))
            ax.plot(ts, bg_stimulus*scale, 'b-.', alpha=0.4)
            plt.legend()
        print 'plotted', data.fdata.filename
        figure.set_size_inches(6,6)
        figure.savefig(os.path.basename(data.fdata.filename)+'.hist.png')
    return figures

def randomized_spike_rasters_allcelltype(category_map, data_map, cellcounts, colordict):
    """Display spike rasters for all cell types with randomized
    labels.

    category_map: map from cellcounts to data file paths with that count

    data_map: map from file paths to {cellname: spike train} dict

    cellcounts: cellcount_tuple specifying number of cells to plot for each cell type

    colordict: map from celltype to color-string for the plot color

    """
    cellcounts = cellcounts._asdict()
    file_category_map = invert_container_map(category_map)
    files = file_category_map.keys()
    random.shuffle(files)
    stim_data = load_stim_data(files)
    simtimes = get_simtime(files)
    file_figtitle_map = {}
    file_fig_map = {}    
    for figindex, fname in enumerate(files):
        fig = plt.figure(figindex+1)
        file_fig_map[fname] = fig
        file_figtitle_map[fname] = figindex + 1
        fdata = data_map[fname]
        cc = defaultdict(list) # dict from cell type to cells
        cells = sorted(fdata.keys())                
        celltype_cell_map = classify_cells(cells)
        cells_to_plot = []
        for celltype, cells in celltype_cell_map.items():
            cells_to_plot += cells[:cellcounts[celltype]]
        data_to_plot = [fdata[cell] for cell in cells_to_plot]
        plot_spike_rasters(cells_to_plot, data_to_plot, colordict)
        plt.plot(np.linspace(0, simtimes[fname], len(stim_data[fname][0])), stim_data[fname][0]*1e9*len(cells_to_plot), alpha=0.2)
    with open('filetofigure_%s.csv' % 
              (datetime.now().strftime('%Y%m%d_%H%M%S')), 'w') as fd:        
        fd.write('filename, figure, %s\n' % (', '.join(cellcount_tuple._fields)))
        for cc, files in category_map.items():
            for x in cc:
                print x
                print str(x)
            counts = ', '.join([str(c) for c in cc])
            print counts
            for fname in files:
                fd.write('%s, %d, %s\n' % (fname, file_figtitle_map[fname], counts))
    plt.show()
    for filename, figure in file_fig_map.items():
        figure.set_size_inches(4, 3)
        figfile = os.path.basename(filename)+'.png'
        figure.savefig(figfile)
        print 'Saved', figfile
        
if __name__ == '__main__':    
    filenames = find_files('/data/subha/rsync_ghevar_cortical_data_clone', '-iname', 'data_*.h5') # Find all data files in the directory
    current_fts = get_fname_timestamps(filenames, '20120918', '20121201') # These simulations were done from 2012-09-19 till 2012-11-??
    notes = get_notes_from_files(current_fts.keys())
    print '=== printing filenames and notes ==='
    for k, v in notes.items():
        print '^', k, v
    print '---'
    categories = classify_files_by_cellcount(current_fts.keys())
    # After categorising the good files, we work with only those files
    # with 240 spiny stellate cells (others test simulations)
    goodfiles = {cc: files for cc, files in categories.items() if cc.SpinyStellate == 240}
    colordict = load_celltype_colors()
    data = [TraubData(filename) for filenamelist in goodfiles.values() for filename in filenamelist]
    print 'Loaded data'
    for d in data:
        print d.fdata.filename
        print d.bg_cells
        print d.probe_cells

    #============================================================
    # The following code plots population spike count histogram
    # start = 15.0
    # end = 20.0 + data[0].simdt
    # plot_population_spike_histogram(data, (start, end), np.arange(start, end, 5e-3), colordict)
    # print 'Created plots'
    # plt.show()
    # Population spike count histogram till here
    #============================================================
    # The following code is for plotting spike rasters for SpinyStellate and TCR cells
    # cellcounts=cellcount_tuple(SupPyrRS=0,
    #                            SupPyrFRB=0,
    #                            SupBasket=0,
    #                            SupAxoaxonic=0,
    #                            SupLTS=0,
    #                            SpinyStellate=240,
    #                            TuftedIB=0,
    #                            TuftedRS=0,
    #                            DeepBasket=0,
    #                            DeepAxoaxonic=0,
    #                            DeepLTS=0,
    #                            NontuftedRS=0,
    #                            TCR=100,
    #                            nRT=0)
    # data = {}
    # for cc, fnames in goodfiles.items():        
    #     data.update(load_spike_data(fnames))
    # print 'Loaded data from', len(data), 'files'
    # randomized_spike_rasters_allcelltype(goodfiles, data, cellcounts, colordict)
    # Till here
    #============================================================
        
                
# 
# analyze_excitation_inhibition_balance.py ends here
